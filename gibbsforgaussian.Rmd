
  
---
title: "dynamic GBEM"
author: "wangzhuofan"
date: "2020/6/11"
output: html_document
---
```{r}
#library(mlegp)
library(MASS)
library(mvtnorm)
library(BayesLogit)
library(reshape2)
library(zoo)
```


--------generating data----------


```{r}
#set parameters
T <-1:40
n <- 15
gmu <- 0.01
gx <- 0.01
```

```{R}
#get function of exponential covariance matrix
covm <- function(g,k,t1,t2){
  res <- g*exp(-k*(t1-t2)^2)
  return(res)
}
```

```{R}
#get function of gaussian process samples
gp <- function(from,to,g,k,K,start,m){
  t <- seq(from=from,to=to,length.out = m)
  Sigma <- sapply(t, function(t1){
    sapply(t, function(t2){
      K(g,k,t1,t2)
    })
  })
  path <- mvrnorm(mu = rep(0,times=m),Sigma=Sigma)
  if(!is.null(start))
    path <- path-path[1]+start
  return(as.vector(path))
}
```

```{R}
#generating mu prior,x1_prior,x2_prior
mupri <- gp(T[1],T[length(T)],1,0.01,covm,NULL,length(T))
x1 <- matrix(0,nrow = n,ncol = length(T))
x2 <- matrix(0,nrow = n,ncol = length(T))
for (i in (1:n)) {
  x1[i,] <- gp(T[1],T[length(T)],1,0.01,covm,NULL,length(T))
  x2[i,] <- gp(T[1],T[length(T)],1,0.01,covm,NULL,length(T))
}
x <- list("x1"=x1,"x2"=x2)
```

```{r}
d <- data.frame("t" <- T,"path"=mupri)
plot(d,type="l")
```

```{r}
#generating s_{ijt},pi_{ijt},y_{ijt}
s <- list()
pi <- list()
y <- list()
for (t in (T)) {
  temp1 <- matrix(0,nrow = n,ncol = n)
  
  temp2 <- matrix(0,nrow = n,ncol = n)
  temp3 <- matrix(0,nrow = n,ncol = n)
  for (i in (2:n)) {
    for (j in (1:(i-1))) {
      temp1[i,j] <- mupri[t]+x1[i,t]*x1[j,t]#+x2[i,t]*x2[j,t]
      temp2[i,j] <- 1/(1+exp(-temp1[i,j]))
      temp3[i,j] <- rbinom(1,1,temp2[i,j])
    }
  }
  s[[t]] <- temp1
  pi[[t]] <- temp2
  y[[t]] <- temp3
}
z <- array(0,dim = c(n,n,length(T)))
for (t in T) {
  for (i in (2:n)) {
    for (j in (1:i)) {
      z[i,j,t] <- y[[t]][i,j]
    }
  }
}
y <- z
```


-----------derive the posterior distribution------------


```{r}
#set parameters
T <- 1:40
H <- 10
kmu <- 0.1 
kx <- 0.1
a1 <- 2
a2 <- 2
iterations <- 1000
```

all the parameters involved are "shrinkage hyperparameter"gamma,"latent variables"x,"baseline"mu,"augmented data"w.

```{r}
#get the prior/initial
KMU <- sapply(T, function(t1){
    sapply(T, function(t2){
      covm(1,kmu,t1,t2)
    })
  })
KX <- sapply(T, function(t1){
    sapply(T, function(t2){
      covm(1,kx,t1,t2)
    })
  })
#initials
#v <- vector()
#v[1] <- rgamma(1,a1)
#v[2:H] <- rgamma((H-1),a2)
#gamma <- cumprod(v)
w <- array(0,dim = c(n,n,length(T)))
x <- array(0,dim = c(n,H,length(T)))
mu <- gp(T[1],T[length(T)],1,kmu,covm,NULL,length(T))
for (h in (1:H)) {
  for (i in (1:n)) {
    x[i,h,] <- gp(T[1],T[length(T)],1,kx,covm,NULL,length(T))
  }
}
```

```{r}
d <- data.frame("t" <- T,"path"=mu)
plot(d,type="l")
```
get the functions

```{r}
#function to compute the augmented data w
#step 1
w_ijt <- function(mu,x,w,y){
  murs <- w
  for (t in T) {
    
    for (i in (2:n)) {
      for (j in (1:(i-1))) {
        w[i,j,t] <- mu[t]
        for (h in (1:H)) {
          w[i,j,t] <- w[i,j,t]+x[i,h,t]*x[j,h,t]
        }
        w[i,j,t] <- rpg(h=1,z=w[i,j,t])
        murs[i,j,t] <- y[i,j,t]-0.5-w[i,j,t]*as.numeric(x[i,,t]%*%x[j,,t])
      }
    }
  }
  w_murs <- list("w"=w,"murs"=murs)
  return(w_murs)
}
#function to compute baseline mu
#step 2
mu_t <- function(w,murs,KMU){
  wdiag <- vector()
  mur <-vector()
  for (t in T) {
    wdiag[t] <- sum(w[,,t])
    mur[t] <- sum(murs[,,t])
  }
  sigmamu <- solve(diag(wdiag)+solve(KMU))
  mumu <- sigmamu%*%mur
  mu <- mvrnorm(mu =mumu,Sigma = sigmamu)
  mu_wdiag <- list("mu"=mu,"wdiag"=wdiag)
  return(mu_wdiag)
}
#function to compute new x
#step 3
x_ijt <- function(mu,wdiag,w,x,KX,gamma,y){
  for (v in (1:n)) {
    yv <- vector()
    x_v <- vector()
    for (i in (1:n)) {
      
      if(i!=v){
        r <- vector()
        for (h in (1:H)) {
          temp <- diag(x[i,h,])
          r <- cbind(r,temp)
        }
        yv <- c(yv,y[max(i,v),min(i,v),])
        x_v <- rbind(x_v,r)
      }
       
    }
  
    omega <- diag(rep(wdiag,n-1))
    test <- t(x_v)%*%omega%*%x_v+kronecker(diag(gamma),solve(KX))
    #while(det(test)<=1e-10){
     # diag(test) <- diag(test)+0.01
    #}
    sigmav <- ginv(test)
    muvr <- yv-kronecker(rep(1,n-1),rep(0.5,length(T)))-as.vector(omega%*%kronecker(rep(1,n-1),mu))
    xv <- mvrnorm(mu = as.vector(sigmav%*%t(x_v)%*%muvr),Sigma = sigmav)
    x[v,,] <- matrix(xv,ncol = length(T))
  }
  return(x)
}
#function to update shrinkage hyperparameters gamma
#step 4
v_h <- function(v,gamma,KX,x){
  v <- rep(1,H)
  for (l in (1:H)) {
    for (i in (1:n)) {
      v[1] <- v[1]+0.5*(gamma[H]/v[1])*x[i,l,]%*%solve(KX)%*%x[i,l,]
    }
  }
  v[1] <- rgamma(n=1,shape = (a1+n*length(T)*H/2),rate = v[1])
  for (h in (2:H)) {
    for (l in (h:H)) {
      for (i in (1:n)) {
        v[h] <- v[h]+0.5*(gamma[H]/v[h])*x[i,l,]%*%solve(KX)%*%x[i,l,]
      }
    }
    v[h] <- rgamma(n=1,shape=a2+n*length(T)*(H-h+1)/2,rate = v[h])
  }
  gamma <- cumprod(v)
  v_gamma <- list("v"=v,"gamma"=gamma)
  return(v_gamma)
}
```
define gibbs sampling 
```{r}
pg_gibbs <- function(T,H,a1,a2,KX,KMU,y,iterations,v_init,gamma_init,w_init,x_init,mu_init){
  T<-T
  H <- H
  a1<- a1
  a2<- a2
  KX <- KX
  KMU <- KMU
  y <- y
  iterations <- iterations
  v <- v_init
  gamma <- gamma_init
  w <- w_init
  x <- x_init
  mu <- mu_init
  resultmu <- matrix(0,nrow = length(T),ncol = iterations)
  
  for (k in (1:iterations)) {
    w_and_mur <- w_ijt(mu=mu,x=x,w=w,y=y)
    w <- w_and_mur$w
    murs <- w_and_mur$murs
    mu_and_wdiag <- mu_t(w= w,murs=murs,KMU = KMU)
    mu <- mu_and_wdiag$mu
    wdiag <- mu_and_wdiag$wdiag
    x <- x_ijt(mu = mu,wdiag=wdiag,w=w,x=x,KX=KX,gamma = gamma,y=y)
    v <- v_h(v=v,gamma = gamma,KX=KX,x=x)$v
    gamma <- v_h(v=v,gamma = gamma,KX=KX,x=x)$gamma
    resultmu[,k] <- mu
  }
  post <- list("mu"=mu,"x"=x)
  return(resultmu)
}
```

```{r}
system.time(pg_gibbs(T=T,H=H,a1=a1,a2=a2,KX=KX,KMU=KMU,y=y,iterations=iterations,v_init=v,gamma_init=gamma,w_init=w,x_init=x,mu_init=mu))
#mu_est001 <- apply(result001[,-(1:1000)],1,mean)
````

```{r}
result <- pg_gibbs(T=T,H=H,a1=a1,a2=a2,KX=KX,KMU=KMU,y=y,iterations=iterations,v_init=v,gamma_init=gamma,w_init=w,x_init=x,mu_init=mu)
result6 <- result[,1001:2000]
mu_est <- apply(result[,1001:2000],1,mean)
#x_est <- result$x

```
```{r}
plot(result6[3,])

```
```{r}
plot(mu_est001,type = "l")
lines(mupri,lty=3)
#plot(mu-mu_est)
```

---------financial co-movement data---------
derive the 23 main national stock market indices quarterly log-returns from 2004 to 2013,about 23*40 data.
```{r}
#derive Y from co-movement data z_{i,t}
v <- 23
T <- 1:40
z <- read.csv("C://ISBD/2020暑假/dynamic graph/week2/23-40yahoo finance.csv")
del <- c(24,25)
z <- z[-del,]
rownames(z) <- z[,1]
delc <- c(1,2)
z <- z[,-delc]
Y_f <- array(NA,dim =c(v,v,length(T)))
for (t in T) {
  for (i in (2:v)) {
    for (j in (1:i)) {
      if(z[i,t]*z[j,t] >0)
        Y_f[i,j,t] <-1
      else
        Y_f[i,j,t] <- 0
    }
  }
}
```

```{r}
#set parameters
T <- 1:40
H <- 15
kmu <- 0.1
kx <- 0.1
a1 <- 2
a2 <- 2
iterations <- 10
n <- v
```

all the parameters involved are "shrinkage hyperparameter"gamma,"latent variables"x,"baseline"mu,"augmented data"w.

```{r}
#get the prior/initial
KMU <- sapply(T, function(t1){
    sapply(T, function(t2){
      covm(1,kmu,t1,t2)
    })
  })
KX <- sapply(T, function(t1){
    sapply(T, function(t2){
      covm(1,kx,t1,t2)
    })
  })
#initials
v <- vector()
v[1] <- rgamma(1,a1)
v[2:H] <- rgamma((H-1),a2)
gamma <- cumprod(v)
w <- array(rep(0,n*n*length(T)),dim = c(n,n,length(T)))
x <- array(rep(0,n*H*length(T)),dim = c(n,H,length(T)))
mu <- gp(T[1],T[length(T)],1,kmu,covm,NULL,length(T))
for (h in (1:H)) {
  for (i in (1:n)) {
    x[i,h,] <- gp(T[1],T[length(T)],1,kx,covm,NULL,length(T))
  }
}
```

```{r}
result_finance <- pg_gibbs(T=T,H=H,a1=a1,a2=a2,KX=KX,KMU=KMU,y=Y_f,iterations=iterations,v_init=v,gamma_init=gamma,w_init=w,x_init=x,mu_init=mu)
mu_est <- result_finance$mu
x_est <- result_finance$x
```

```{r}
df <- data.frame("time"=as.yearqtr(2004+seq(0,(2013-2004+1)*4-1)/4),"mu"=mu_est)
plot(df,type = "l")
lines(mu,lty=3)
plot(mu-mu_est)
```
